{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# DAE : Does Denoising Autoencoder\n\ncredits: https://www.kaggle.com/adegladius/tbapril21-data\nhttps://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler","metadata":{}},{"cell_type":"code","source":"# imports\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nimport warnings\n\n","metadata":{"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"!pip install kaggler","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting kaggler\n  Downloading Kaggler-0.9.4.tar.gz (820 kB)\n\u001b[K     |████████████████████████████████| 820 kB 4.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from kaggler) (2.4.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from kaggler) (0.29.22)\nRequirement already satisfied: hyperopt in /opt/conda/lib/python3.7/site-packages (from kaggler) (0.2.5)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (from kaggler) (3.1.1)\nRequirement already satisfied: ml-metrics in /opt/conda/lib/python3.7/site-packages (from kaggler) (0.1.4)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from kaggler) (0.12.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kaggler) (3.4.0)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (from kaggler) (1.5.12)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (from kaggler) (1.3.3)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (0.18.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (1.15.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (1.19.5)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (2.5)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (1.6.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (1.5.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from hyperopt->kaggler) (4.56.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt->kaggler) (4.4.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->kaggler) (2.25.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle->kaggler) (4.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->kaggler) (1.26.3)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->kaggler) (2.8.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->kaggler) (2020.12.5)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm->kaggler) (0.36.2)\nRequirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.7/site-packages (from lightgbm->kaggler) (0.24.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->kaggler) (2.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->kaggler) (1.0.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kaggler) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kaggler) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kaggler) (1.3.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kaggler) (7.2.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ml-metrics->kaggler) (1.2.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ml-metrics->kaggler) (2021.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle->kaggler) (1.3)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->kaggler) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->kaggler) (3.0.4)\nRequirement already satisfied: patsy>=0.5 in /opt/conda/lib/python3.7/site-packages (from statsmodels->kaggler) (0.5.1)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.12.1)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (2.4.1)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.12)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.1.2)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.32.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (3.7.4.3)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (2.4.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.1.0)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (0.3.3)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (1.6.3)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (2.10.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (3.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (3.15.6)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (0.12.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->kaggler) (0.2.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (1.24.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (0.4.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (1.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (3.3.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->kaggler) (49.6.0.post20210108)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->kaggler) (4.7.1)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->kaggler) (4.2.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->kaggler) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->kaggler) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->kaggler) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->kaggler) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->kaggler) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow->kaggler) (3.4.0)\nBuilding wheels for collected packages: kaggler\n  Building wheel for kaggler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kaggler: filename=Kaggler-0.9.4-cp37-cp37m-linux_x86_64.whl size=2958497 sha256=1073e588853cb66f9d287a56ee0512a6349dcc75e7d76c10cf9717522a8dd293\n  Stored in directory: /root/.cache/pip/wheels/7e/ef/b7/f249348c07943183235167e6208e3a3571cfa96ae2f8218d6c\nSuccessfully built kaggler\nInstalling collected packages: kaggler\nSuccessfully installed kaggler-0.9.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import kaggler\nfrom kaggler.model import AutoLGB\nfrom kaggler.preprocessing import DAE, TargetEncoder, LabelEncoder\n\nprint(f'Kaggler: {kaggler.__version__}')\n","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Kaggler: 0.9.4\n","output_type":"stream"}]},{"cell_type":"code","source":"warnings.simplefilter('ignore')\npd.set_option('max_columns', 100)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"feature_name = 'dae_te'\nalgo_name = 'lgb'\nmodel_name = f'{algo_name}_{feature_name}'\n\ndata_dir = Path('/kaggle/input/tabular-playground-series-apr-2021/')\ntrn_file = '../input/tbapril21-data/train_titanic_tb.csv'\ntst_file = '../input/tbapril21-data/test_titanic_tb.csv'\nsample_file = '../input/tbapril21-data/sample_submission_tb.csv'\npseudo_label_file = '../input/tps-apr-2021-pseudo-label-dae/REMEK-TPS04-FINAL005.csv'\n\nfeature_file = f'{feature_name}.csv'\npredict_val_file = f'{model_name}.val.txt'\npredict_tst_file = f'{model_name}.tst.txt'\nsubmission_file = f'{model_name}.sub.csv'\n\ntarget_col = 'Survived'\nid_col = 'PassengerId'\n","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"n_fold = 5\nseed = 42\nencoding_dim = 64","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trn = pd.read_csv(trn_file, index_col=id_col)\ntst = pd.read_csv(tst_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\npseudo_label = pd.read_csv(pseudo_label_file, index_col=id_col)\nprint(trn.shape, tst.shape, sub.shape, pseudo_label.shape)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(100000, 11) (100000, 10) (100000, 1) (100000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"tst[target_col] = pseudo_label[target_col]\nn_trn = trn.shape[0]\ndf = pd.concat([trn, tst], axis=0)\ndf.head()\n","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"             Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\nPassengerId                                                                  \n0                   1       1  Oconnor, Frankie  male    NaN      2      0   \n1                   0       3       Bryan, Drew  male    NaN      0      0   \n2                   0       3    Owens, Kenneth  male   0.33      1      2   \n3                   0       3     Kramer, James  male  19.00      0      0   \n4                   1       3     Bond, Michael  male  25.00      0      0   \n\n                Ticket   Fare   Cabin Embarked  \nPassengerId                                     \n0               209245  27.14  C12239        S  \n1                27323  13.35     NaN        S  \n2            CA 457703  71.29     NaN        S  \n3             A. 10866  13.04     NaN        S  \n4               427635   7.76     NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Oconnor, Frankie</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>209245</td>\n      <td>27.14</td>\n      <td>C12239</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Bryan, Drew</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27323</td>\n      <td>13.35</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Owens, Kenneth</td>\n      <td>male</td>\n      <td>0.33</td>\n      <td>1</td>\n      <td>2</td>\n      <td>CA 457703</td>\n      <td>71.29</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Kramer, James</td>\n      <td>male</td>\n      <td>19.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A. 10866</td>\n      <td>13.04</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Bond, Michael</td>\n      <td>male</td>\n      <td>25.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>427635</td>\n      <td>7.76</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Feature engineering code from https://www.kaggle.com/udbhavpangotra/tps-apr21-eda-model\n\ndf['Embarked'] = df['Embarked'].fillna('No')\ndf['Cabin'] = df['Cabin'].fillna('_')\ndf['CabinType'] = df['Cabin'].apply(lambda x:x[0])\ndf.Ticket = df.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\ndf['Age'].fillna(round(df['Age'].median()), inplace=True,)\ndf['Age'] = df['Age'].apply(round).astype(int)\n\n# Fare, fillna with mean value\nfare_map = df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\ndf['Fare'] = df['Fare'].fillna(df['Pclass'].map(fare_map['Fare']))\n\ndf['FirstName'] = df['Name'].str.split(', ').str[0]\ndf['SecondName'] = df['Name'].str.split(', ').str[1]\n\ndf['n'] = 1\n\ngb = df.groupby('FirstName')\ndf_names = gb['n'].sum()\ndf['SameFirstName'] = df['FirstName'].apply(lambda x:df_names[x]).fillna(1)\n\ngb = df.groupby('SecondName')\ndf_names = gb['n'].sum()\ndf['SameSecondName'] = df['SecondName'].apply(lambda x:df_names[x]).fillna(1)\n\ndf['Sex'] = (df['Sex'] == 'male').astype(int)\n\ndf['FamilySize'] = df.SibSp + df.Parch + 1\n\nfeature_cols = ['Pclass', 'Age','Embarked','Parch','SibSp','Fare','CabinType','Ticket','SameFirstName', 'SameSecondName', 'Sex',\n                'FamilySize', 'FirstName', 'SecondName']\ncat_cols = ['Pclass','Embarked','CabinType','Ticket', 'FirstName', 'SecondName']\nnum_cols = [x for x in feature_cols if x not in cat_cols]\nprint(len(feature_cols), len(cat_cols), len(num_cols))","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"14 6 8\n","output_type":"stream"}]},{"cell_type":"code","source":"for col in ['SameFirstName', 'SameSecondName', 'Fare', 'FamilySize', 'Parch', 'SibSp']:\n    df[col] = np.log2(1 + df[col])\n    \nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Label encoding with rare category grouping and missing value imputation","metadata":{}},{"cell_type":"code","source":"lbe = LabelEncoder(min_obs=50)\ndf[cat_cols] = lbe.fit_transform(df[cat_cols]).astype(int)\n","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Target encoding with smoothing and 5-fold cross-validation","metadata":{}},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\nte = TargetEncoder(cv=cv)\ndf_te = te.fit_transform(df[cat_cols], df[target_col])\ndf_te.columns = [f'te_{col}' for col in cat_cols]\ndf_te.head()\n","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             te_Pclass  te_Embarked  te_CabinType  te_Ticket  te_FirstName  \\\nPassengerId                                                                  \n0             0.590054     0.263077      0.725503   0.362868      0.385527   \n1             0.385600     0.385600      0.385600   0.385600      0.385600   \n2             0.237340     0.263239      0.282278   0.269231      0.410853   \n3             0.238793     0.263077      0.284236   0.098983      0.523807   \n4             0.237259     0.263630      0.282163   0.363188      0.385958   \n\n             te_SecondName  \nPassengerId                 \n0                 0.318182  \n1                 0.385600  \n2                 0.143337  \n3                 0.146459  \n4                 0.143773  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>te_Pclass</th>\n      <th>te_Embarked</th>\n      <th>te_CabinType</th>\n      <th>te_Ticket</th>\n      <th>te_FirstName</th>\n      <th>te_SecondName</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.590054</td>\n      <td>0.263077</td>\n      <td>0.725503</td>\n      <td>0.362868</td>\n      <td>0.385527</td>\n      <td>0.318182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.385600</td>\n      <td>0.385600</td>\n      <td>0.385600</td>\n      <td>0.385600</td>\n      <td>0.385600</td>\n      <td>0.385600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.237340</td>\n      <td>0.263239</td>\n      <td>0.282278</td>\n      <td>0.269231</td>\n      <td>0.410853</td>\n      <td>0.143337</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.238793</td>\n      <td>0.263077</td>\n      <td>0.284236</td>\n      <td>0.098983</td>\n      <td>0.523807</td>\n      <td>0.146459</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.237259</td>\n      <td>0.263630</td>\n      <td>0.282163</td>\n      <td>0.363188</td>\n      <td>0.385958</td>\n      <td>0.143773</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"DAE","metadata":{}},{"cell_type":"code","source":"dae = DAE(cat_cols=cat_cols, num_cols=num_cols, encoding_dim=encoding_dim)\nX = dae.fit_transform(df[feature_cols])","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/100\n157/157 [==============================] - 3s 11ms/step - loss: 0.1071 - val_loss: 0.0079\nEpoch 2/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0360 - val_loss: 0.0053\nEpoch 3/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0312 - val_loss: 0.0050\nEpoch 4/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0300 - val_loss: 0.0046\nEpoch 5/100\n157/157 [==============================] - 2s 10ms/step - loss: 0.0293 - val_loss: 0.0042\nEpoch 6/100\n157/157 [==============================] - 2s 10ms/step - loss: 0.0285 - val_loss: 0.0039\nEpoch 7/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0279 - val_loss: 0.0039\nEpoch 8/100\n157/157 [==============================] - 1s 10ms/step - loss: 0.0277 - val_loss: 0.0036\nEpoch 9/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0275 - val_loss: 0.0036\nEpoch 10/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0271 - val_loss: 0.0035\nEpoch 11/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0269 - val_loss: 0.0034\nEpoch 12/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0268 - val_loss: 0.0034\nEpoch 13/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0264 - val_loss: 0.0033\nEpoch 14/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0264 - val_loss: 0.0033\nEpoch 15/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0262 - val_loss: 0.0033\nEpoch 16/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0260 - val_loss: 0.0031\nEpoch 17/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0257 - val_loss: 0.0032\nEpoch 18/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0255 - val_loss: 0.0031\nEpoch 19/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0253 - val_loss: 0.0030\nEpoch 20/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0255 - val_loss: 0.0030\nEpoch 21/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0250 - val_loss: 0.0029\nEpoch 22/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0253 - val_loss: 0.0029\nEpoch 23/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0251 - val_loss: 0.0028\nEpoch 24/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0249 - val_loss: 0.0028\nEpoch 25/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0249 - val_loss: 0.0029\nEpoch 26/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0028\nEpoch 27/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0248 - val_loss: 0.0027\nEpoch 28/100\n157/157 [==============================] - 2s 11ms/step - loss: 0.0246 - val_loss: 0.0027\nEpoch 29/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0027\nEpoch 30/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0249 - val_loss: 0.0027\nEpoch 31/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0246 - val_loss: 0.0027\nEpoch 32/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0248 - val_loss: 0.0027\nEpoch 33/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0027\nEpoch 34/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0027\nEpoch 35/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0027\nEpoch 36/100\n157/157 [==============================] - 2s 10ms/step - loss: 0.0246 - val_loss: 0.0027\nEpoch 37/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0027\nEpoch 38/100\n157/157 [==============================] - 2s 10ms/step - loss: 0.0246 - val_loss: 0.0027\nEpoch 39/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0027\nEpoch 40/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0027\nEpoch 41/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0027\nEpoch 42/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0027\nEpoch 43/100\n157/157 [==============================] - 2s 10ms/step - loss: 0.0245 - val_loss: 0.0027\nEpoch 44/100\n157/157 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0027\nRestoring model weights from the end of the best epoch.\nEpoch 00044: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"df_dae = pd.DataFrame(X, columns=[f'dae_{i}' for i in range(encoding_dim)])\nprint(df_dae.shape)\n","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(200000, 64)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Part 2: Model Training\n\nAutoLGB for Feature Selection and Hyperparameter Optimization","metadata":{}},{"cell_type":"code","source":"X = pd.concat([df[feature_cols], df_te, df_dae], axis=1)\ny = df[target_col]\nX_tst = X.iloc[n_trn:]\n\np = np.zeros_like(y, dtype=float)\np_tst = np.zeros((tst.shape[0],))\nprint(f'Training a stacking ensemble LightGBM model:')\nfor i, (i_trn, i_val) in enumerate(cv.split(X, y)):\n    if i == 0:\n        clf = AutoLGB(objective='binary', metric='auc', sample_size=len(i_trn), random_state=seed)\n        clf.tune(X.iloc[i_trn], y[i_trn])\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n    \n    trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn])\n    val_data = lgb.Dataset(X.iloc[i_val], y[i_val])\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    p[i_val] = clf.predict(X.iloc[i_val])\n    p_tst += clf.predict(X_tst) / n_fold\n    print(f'CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}')\n","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Training a stacking ensemble LightGBM model:\n100%|██████████| 10/10 [00:35<00:00,  3.54s/trial, best loss: -0.9379150852807484]\n100%|██████████| 100/100 [08:38<00:00,  5.18s/trial, best loss: -0.9381988224079066]\n429\n{'bagging_freq': 1, 'verbosity': -1, 'seed': 42, 'num_threads': -1, 'feature_pre_filter': False, 'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'bagging_fraction': 0.9, 'feature_fraction': 0.8, 'lambda_l1': 1, 'lambda_l2': 0, 'learning_rate': 0.016462967247240133, 'max_depth': 8, 'min_child_samples': 10, 'num_leaves': 127}\n['Sex', 'Embarked', 'te_CabinType', 'Pclass', 'CabinType', 'dae_52', 'te_Ticket', 'dae_41', 'Fare', 'Ticket', 'te_Embarked', 'dae_60', 'te_SecondName', 'Age', 'te_Pclass', 'dae_32', 'dae_18', 'dae_46', 'dae_21', 'dae_6', 'dae_29', 'dae_59', 'dae_26', 'dae_53', 'dae_35', 'dae_5', 'dae_2', 'dae_62', 'dae_14', 'dae_38', 'dae_12', 'dae_55']\n[100]\tvalid_0's auc: 0.937772\n[200]\tvalid_0's auc: 0.938963\n[300]\tvalid_0's auc: 0.939564\n[400]\tvalid_0's auc: 0.939639\nCV #1 AUC: 0.939601\n[100]\tvalid_0's auc: 0.937344\n[200]\tvalid_0's auc: 0.938834\n[300]\tvalid_0's auc: 0.939638\n[400]\tvalid_0's auc: 0.939751\nCV #2 AUC: 0.939771\n[100]\tvalid_0's auc: 0.936894\n[200]\tvalid_0's auc: 0.938631\n[300]\tvalid_0's auc: 0.939554\n[400]\tvalid_0's auc: 0.939812\nCV #3 AUC: 0.939806\n[100]\tvalid_0's auc: 0.935499\n[200]\tvalid_0's auc: 0.937102\n[300]\tvalid_0's auc: 0.93796\n[400]\tvalid_0's auc: 0.938158\nCV #4 AUC: 0.938142\n[100]\tvalid_0's auc: 0.917892\n[200]\tvalid_0's auc: 0.918732\n[300]\tvalid_0's auc: 0.91919\n[400]\tvalid_0's auc: 0.91889\nCV #5 AUC: 0.918892\n","output_type":"stream"}]},{"cell_type":"code","source":"np.savetxt(predict_val_file, p, fmt='%.6f')\nnp.savetxt(predict_tst_file, p_tst, fmt='%.6f')\n","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(f'  CV AUC: {roc_auc_score(y, p):.6f}')\nprint(f'Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}')","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"  CV AUC: 0.935012\nTest AUC: 0.9999363121805189\n","output_type":"stream"}]},{"cell_type":"code","source":"n_pos = int(0.34911 * tst.shape[0])\nth = sorted(p_tst, reverse=True)[n_pos]\nprint(th)\nconfusion_matrix(pseudo_label[target_col], (p_tst > th).astype(int))\n","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0.32484361188468314\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array([[65069,   586],\n       [   20, 34325]])"},"metadata":{}}]},{"cell_type":"code","source":"sub[target_col] = (p_tst > th).astype(int)\nsub.to_csv(submission_file)","metadata":{"trusted":true},"execution_count":26,"outputs":[]}]}